{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ca5c73b",
   "metadata": {},
   "source": [
    "## Configure your environment\n",
    "\n",
    "Download the following file on your computer :\n",
    "\n",
    "https://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken\n",
    "\n",
    "This model file is required by langchain for the tokenisation (slashing words in subparts before embedding).\n",
    "\n",
    "rename it `9b5ad71b2ce5302211f9c61530b329a4922fc6a4` (no extension).\n",
    "\n",
    "Create a new directory in your space called `tiktoken_cache`.\n",
    "\n",
    "\n",
    "Upload the file in this directory :\n",
    "\n",
    "\n",
    "```\n",
    "üìÅ tiktoken_cache\n",
    " ‚îî‚îÄ‚îÄ üìÑ 9b5ad71b2ce5302211f9c61530b329a4922fc6a4\n",
    "```\n",
    "\n",
    "You then must set the `TIKTOKEN_CACHE_DIR` env variable as `tiktoken_cache` (see [Configure your Azure Environment](#Configure-your-Azure-Environment)).\n",
    "\n",
    "Make sure to change the following variables accordingly to your environment : \n",
    "- `AZURE_OPENAI_ENDPOINT` should be changed to `https://aoai-<your-oai-prefix>.openai.azure.com`\n",
    "- `OPENAI_API_VERSION` should be updated to the latest version\n",
    "- `GPT_ENGINE` should be changed to your desired GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "326d0551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://d63486:****@artifactory.cib.echonet/artifactory/api/pypi/pypi-remote/simple\n",
      "Requirement already satisfied: langchain_mistralai in /opt/conda/envs/PP_new/lib/python3.12/site-packages (0.2.9)\n",
      "Requirement already satisfied: pdfplumber in /opt/conda/envs/PP_new/lib/python3.12/site-packages (0.11.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain_mistralai) (0.3.49)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15.1 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain_mistralai) (0.21.1)\n",
      "Requirement already satisfied: httpx<1,>=0.25.2 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain_mistralai) (0.27.2)\n",
      "Requirement already satisfied: httpx-sse<1,>=0.3.1 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain_mistralai) (0.4.0)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain_mistralai) (2.10.6)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (43.0.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from httpx<1,>=0.25.2->langchain_mistralai) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.25.2->langchain_mistralai) (0.14.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (0.1.129)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (4.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pydantic<3,>=2->langchain_mistralai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from pydantic<3,>=2->langchain_mistralai) (2.27.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from tokenizers<1,>=0.15.1->langchain_mistralai) (0.25.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2024.3.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (4.66.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_mistralai) (3.10.7)\n",
      "Requirement already satisfied: pycparser in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/PP_new/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15.1->langchain_mistralai) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_mistralai pdfplumber\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate,HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.document_loaders import PyPDFLoader, PythonLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import FewShotChatMessagePromptTemplate,ChatPromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.agents import initialize_agent, AgentType, load_tools\n",
    "from httpx_auth import OAuth2ClientCredentials\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever \n",
    "import uuid\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.output_parsers import NumberedListOutputParser\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.document import Document\n",
    "import httpx\n",
    "from httpx_auth import HeaderApiKey\n",
    "import requests\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "import sys\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_mistralai import ChatMistralAI, MistralAIEmbeddings\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.caches import InMemoryCache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4dd817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from httpx_auth import OAuth2ClientCredentials\n",
    "from openai import AzureOpenAI as AzureOpenAINative\n",
    "from langchain_openai import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import hashlib\n",
    "import tiktoken\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f23af390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "AZURE_AOAI_API_VERSION = \"2024-08-01-preview\"\n",
    "AZURE_AOAI_MODEL_GPT3_TURBO = \"gpt35turbo\"\n",
    "AZURE_AOAI_MODEL_GPT4O = \"gpt4o\"\n",
    "AZURE_AOAI_MODEL_GPT4OMINI = \"gpt4omini\"\n",
    "AZURE_EMBEDDING_MODEL = \"text-embedding-ada\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ac040",
   "metadata": {},
   "source": [
    "### Update Tiktoken & add it into envionment variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8421b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tiktoken():\n",
    "\n",
    "    os.environ[\"TIKTOKEN_CACHE_DIR\"] = \"/mnt/tiktoken_cache\"\n",
    "    blobpath = os.environ['TOKEN_BLOB_PATH']\n",
    "    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()\n",
    "    # validate\n",
    "    assert os.path.exists(os.path.join(os.environ[\"TIKTOKEN_CACHE_DIR\"], cache_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08ada9",
   "metadata": {},
   "source": [
    "### Get Authentification Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906dc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auth():\n",
    "\n",
    "    update_tiktoken()\n",
    "\n",
    "    OIDC_ENDPOINT = os.environ[\"OIDC_ENDPOINT\"]\n",
    "    OIDC_CLIENT_ID = os.environ[\"OIDC_CLIENT_ID\"]\n",
    "    OIDC_CLIENT_SECRET = os.environ[\"OIDC_CLIENT_SECRET\"]\n",
    "    OIDC_SCOPE = os.environ[\"OIDC_SCOPE\"]\n",
    "    oauth2_httpxclient=httpx.Client(verify=False)\n",
    "    auth=OAuth2ClientCredentials(OIDC_ENDPOINT, client_id=OIDC_CLIENT_ID, client_secret=OIDC_CLIENT_SECRET, scope=OIDC_SCOPE,client=oauth2_httpxclient)\n",
    "\n",
    "    return auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b3fc3c",
   "metadata": {},
   "source": [
    "### Create native azure openai llm client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "179464f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_openai_native(api_version):\n",
    "\n",
    "    APIGEE_ENDPOINT = os.environ[\"APIGEE_ENDPOINT\"]\n",
    "    AZURE_AOAI_API_VERSION=api_version\n",
    "    auth=get_auth()\n",
    "\n",
    "    client = AzureOpenAINative(\n",
    "        api_version=AZURE_AOAI_API_VERSION,\n",
    "        azure_endpoint=APIGEE_ENDPOINT,\n",
    "        api_key=\"FAKE_KEY\",\n",
    "        http_client=httpx.Client(auth=auth, verify=False),\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf3ae3e",
   "metadata": {},
   "source": [
    "### Create azure openai llm chat model with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecc2a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_chat_langchain(model_name,api_version,temperature=0):\n",
    "    APIGEE_ENDPOINT = os.environ[\"APIGEE_ENDPOINT\"]\n",
    "    auth=get_auth()\n",
    "\n",
    "    client = AzureChatOpenAI(\n",
    "        api_version=api_version,\n",
    "        azure_endpoint=APIGEE_ENDPOINT,\n",
    "        api_key=\"FAKE_KEY\",\n",
    "        http_client=httpx.Client(auth=auth, verify=False),\n",
    "        model=model_name,\n",
    "        temperature = temperature\n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8c71f",
   "metadata": {},
   "source": [
    "### Create azure openai llm model with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55abc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_langchain(model_name,api_version,temperature=0):\n",
    "    APIGEE_ENDPOINT = os.environ[\"APIGEE_ENDPOINT\"]\n",
    "    auth=get_auth()\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        api_version=api_version,\n",
    "        azure_endpoint=APIGEE_ENDPOINT,\n",
    "        api_key=\"FAKE_KEY\",\n",
    "        http_client=httpx.Client(auth=auth, verify=False),\n",
    "        deployment_name=model_name,\n",
    "        temperature = temperature\n",
    "    )\n",
    "\n",
    "    return client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e21a29e",
   "metadata": {},
   "source": [
    "### Create azure openai embeddings with langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d18a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_azureopenai(embedding_model, api_version):\n",
    "\n",
    "\n",
    "    APIGEE_ENDPOINT = os.environ[\"APIGEE_ENDPOINT\"]\n",
    "    auth=get_auth()\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        api_version=api_version,\n",
    "        azure_endpoint=APIGEE_ENDPOINT,\n",
    "        api_key=\"FAKE_KEY\",\n",
    "        http_client=httpx.Client(auth=auth, verify=False),\n",
    "        model=embedding_model\n",
    "\n",
    "    )\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe908916",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3332958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fd9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    Controle Technique des Constructions   Intervention obligatoire v  062021 19 Classification   Confidential 15 9 Transferts internationaux de Donnees a caractere personnel Aucune Donnee a caractere personnel du Maitre d Ouvrage traitee au sein de l EEE par le Controleur technique ou par ses Sous  traitants de second  rang ne peutde second  rang ne peut etre transferee en dehors de l EEE sans l accord ecrit et prealable du Maitre d Ouvrage  Lorsqu un tel ac cord est donne par le Maitre d Ouvrage  il doit etre subordonne a tout transfert effectue  i  aux termes d un accord contraignant  ex  via un avenant au present Contrat  et  ii  a la mise en place deet  ii  a la mise en place de garanties appropriees  ex  les clauses types de l Union europeenne relative au transfert de Donnees a caractere personnel du Responsable de traitement vers un Sous  traitant   Le Controleur technique fournit au Maitre d Ouvrage sans delai et a la demande de celui  ci toute preuve et ou copie destoute preuve et ou copie des points  i  et  ii   ci dessus  15 10 Traitement par le Maitre d Ouvrage des Donnees a caractere personnel du Personnel d u Controleur technique Dans certains cas  le Maitre d Ouvrage peut etre amene a traiter des Donnees a caractere personnel du Personnel du Controleur technique  ex  prenom  nomtechnique  ex  prenom  nom  numero de telephone portable  adresse email   et ce notamment a des fins de securite et de continuite des activites  Le Controleur technique porte a l attention de son Personnel la notice d information de BNP Paribas disponible sur l adresse du site institutionnel de BNP Paribas  group bnpparibas comParibas  group bnpparibas com   jesuis  fournisseur    Le Controleur technique consent au traitement des Donnees a cara ctere personnel du Personnel du Controleur technique par le M\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fed8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_llm_chat_langchain(AZURE_AOAI_MODEL_DEPLOYMENT_NAME,AZURE_AOAI_API_VERSION) # \n",
    "llm2 = create_llm_chat_langchain(AZURE_AOAI_MODEL_DEPLOYMENT_NAME,AZURE_AOAI_API_VERSION) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18972ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x7f206530dd90> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f206530f2c0> root_client=<openai.lib.azure.AzureOpenAI object at 0x7f208059dbb0> root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x7f206530ddc0> model_name='gpt4o' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********') http_client=<httpx.Client object at 0x7f20652a7590> disabled_params={'parallel_tool_calls': None} azure_endpoint='https://aifactory.api.staging.echonet/genai-model/v1' openai_api_version='2024-08-01-preview' openai_api_type='azure'\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "500459d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/PP_new/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dmn-ap26180-prod-1b000272.datalab.cloud.echonet'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/PP_new/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'dmn-ap26180-prod-1b000272.datalab.cloud.echonet'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "APIGEE_ENDPOINT=\"https://aifactory.api.staging.echonet/genai-model/v1\"\n",
    "\n",
    "api_key = \"sk-GMIuv1MaL-IPS-PP-dev\"  # Replace with your real API token\n",
    "headers = {\n",
    "    \"X-Api-Key\": \"sk-GMIuv1MaL-IPS-PP-dev\"  # Replace with your real API token\n",
    "}\n",
    "endpoint = \"https://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/u/903609/llmaas/app\"\n",
    " \n",
    "auth = HeaderApiKey(api_key=api_key)\n",
    "http_client = httpx.Client(auth=auth, verify=False)\n",
    " \n",
    "response = requests.head(endpoint, allow_redirects=True, verify=False)\n",
    "url = response.url\n",
    "client = openai.OpenAI(base_url=url, http_client=http_client, api_key=\"fake_key\")  # The api_key=fake_key is required otherwise OpenAI raises an error\n",
    "\n",
    "client2 = AzureChatOpenAI(\n",
    "        api_version=AZURE_AOAI_API_VERSION,\n",
    "        azure_endpoint=APIGEE_ENDPOINT,\n",
    "        api_key=\"FAKE_KEY\",\n",
    "        http_client=httpx.Client(auth=auth, verify=False),\n",
    "        model=AZURE_AOAI_MODEL_GPT4O,\n",
    "        temperature = 0\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "952893a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "AZURE_AOAI_API_VERSION = \"2024-08-01-preview\"\n",
    "AZURE_AOAI_MODEL_GPT3_TURBO = \"gpt35turbo\"\n",
    "AZURE_AOAI_MODEL_GPT4O = \"gpt4o\"\n",
    "AZURE_AOAI_MODEL_GPT4OMINI = \"gpt4omini\"\n",
    "AZURE_EMBEDDING_MODEL = \"text-embedding-ada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cfa3c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='930c4716bb1d4c64bb41b919fdb95db3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='As of my last update in October 2023, the CEO of BNP Paribas is Jean-Laurent Bonnaf√©. He has been serving in this role since December 2011. However, for the most current information, I recommend checking the latest updates from BNP Paribas or reliable financial news sources.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1743090923, model='mistral/mistral-large-2502', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=71, prompt_tokens=26, total_tokens=97, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.chat.completions.create(\n",
    "            model=\"mistral-large-2407\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant to analyse images.\"},\n",
    "                {\"role\": \"user\",\"content\": \"Who is the CEO of BNP Paribas?\"},\n",
    "            ],\n",
    "            max_tokens=2000,\n",
    "            temperature=0.0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d6c60af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of my last update in October 2023, the CEO of BNP Paribas is Jean-Laurent Bonnaf√©. Please verify with the latest sources as executive positions can change.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 16, 'total_tokens': 55, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_ded0d14823', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-cebbcc3f-a98e-49fd-ae1a-6c69fc57f622-0', usage_metadata={'input_tokens': 16, 'output_tokens': 39, 'total_tokens': 55, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Who is the CEO of BNP Paribas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8386f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AsyncClient.__init__() got an unexpected keyword argument 'proxies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m embeddings \u001b[39m=\u001b[39m create_embeddings_azureopenai(AZURE_EMBEDDING_MODEL,AZURE_AOAI_API_VERSION)\n\u001b[1;32m      <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(embeddings)\n",
      "\u001b[1;32m/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb Cell 22\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m APIGEE_ENDPOINT \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mAPIGEE_ENDPOINT\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m auth\u001b[39m=\u001b[39mget_auth()\n\u001b[0;32m----> <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m embeddings \u001b[39m=\u001b[39m AzureOpenAIEmbeddings(\n\u001b[1;32m      <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     api_version\u001b[39m=\u001b[39mapi_version,\n\u001b[1;32m      <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     azure_endpoint\u001b[39m=\u001b[39mAPIGEE_ENDPOINT,\n\u001b[1;32m     <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFAKE_KEY\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     http_client\u001b[39m=\u001b[39mhttpx\u001b[39m.\u001b[39mClient(auth\u001b[39m=\u001b[39mauth, verify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     model\u001b[39m=\u001b[39membedding_model\n\u001b[1;32m     <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X30sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/PP_new/lib/python3.12/site-packages/langchain_openai/embeddings/azure.py:206\u001b[0m, in \u001b[0;36mAzureOpenAIEmbeddings.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39masync_client:\n\u001b[1;32m    205\u001b[0m     async_specific: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mhttp_client\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhttp_async_client}\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39masync_client \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mAsyncAzureOpenAI(\n\u001b[1;32m    207\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mclient_params,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39masync_specific,\n\u001b[1;32m    209\u001b[0m     )\u001b[39m.\u001b[39membeddings\n\u001b[1;32m    210\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/PP_new/lib/python3.12/site-packages/openai/lib/azure.py:447\u001b[0m, in \u001b[0;36mAsyncAzureOpenAI.__init__\u001b[0;34m(self, azure_endpoint, azure_deployment, api_version, api_key, azure_ad_token, azure_ad_token_provider, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m api_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[39m# define a sentinel value to avoid any typing issues\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     api_key \u001b[39m=\u001b[39m API_KEY_SENTINEL\n\u001b[0;32m--> 447\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    448\u001b[0m     api_key\u001b[39m=\u001b[39mapi_key,\n\u001b[1;32m    449\u001b[0m     organization\u001b[39m=\u001b[39morganization,\n\u001b[1;32m    450\u001b[0m     project\u001b[39m=\u001b[39mproject,\n\u001b[1;32m    451\u001b[0m     base_url\u001b[39m=\u001b[39mbase_url,\n\u001b[1;32m    452\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m    453\u001b[0m     max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[1;32m    454\u001b[0m     default_headers\u001b[39m=\u001b[39mdefault_headers,\n\u001b[1;32m    455\u001b[0m     default_query\u001b[39m=\u001b[39mdefault_query,\n\u001b[1;32m    456\u001b[0m     http_client\u001b[39m=\u001b[39mhttp_client,\n\u001b[1;32m    457\u001b[0m     _strict_response_validation\u001b[39m=\u001b[39m_strict_response_validation,\n\u001b[1;32m    458\u001b[0m )\n\u001b[1;32m    459\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_api_version \u001b[39m=\u001b[39m api_version\n\u001b[1;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_azure_ad_token \u001b[39m=\u001b[39m azure_ad_token\n",
      "File \u001b[0;32m/opt/conda/envs/PP_new/lib/python3.12/site-packages/openai/_client.py:337\u001b[0m, in \u001b[0;36mAsyncOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mif\u001b[39;00m base_url \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     base_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://api.openai.com/v1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 337\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    338\u001b[0m     version\u001b[39m=\u001b[39m__version__,\n\u001b[1;32m    339\u001b[0m     base_url\u001b[39m=\u001b[39mbase_url,\n\u001b[1;32m    340\u001b[0m     max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[1;32m    341\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[1;32m    342\u001b[0m     http_client\u001b[39m=\u001b[39mhttp_client,\n\u001b[1;32m    343\u001b[0m     custom_headers\u001b[39m=\u001b[39mdefault_headers,\n\u001b[1;32m    344\u001b[0m     custom_query\u001b[39m=\u001b[39mdefault_query,\n\u001b[1;32m    345\u001b[0m     _strict_response_validation\u001b[39m=\u001b[39m_strict_response_validation,\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_stream_cls \u001b[39m=\u001b[39m AsyncStream\n\u001b[1;32m    350\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletions \u001b[39m=\u001b[39m resources\u001b[39m.\u001b[39mAsyncCompletions(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/PP_new/lib/python3.12/site-packages/openai/_base_client.py:1437\u001b[0m, in \u001b[0;36mAsyncAPIClient.__init__\u001b[0;34m(self, version, base_url, _strict_response_validation, max_retries, timeout, transport, proxies, limits, http_client, custom_headers, custom_query)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1421\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid `http_client` argument; Expected an instance of `httpx.AsyncClient` but got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(http_client)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1422\u001b[0m     )\n\u001b[1;32m   1424\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m   1425\u001b[0m     version\u001b[39m=\u001b[39mversion,\n\u001b[1;32m   1426\u001b[0m     base_url\u001b[39m=\u001b[39mbase_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1435\u001b[0m     _strict_response_validation\u001b[39m=\u001b[39m_strict_response_validation,\n\u001b[1;32m   1436\u001b[0m )\n\u001b[0;32m-> 1437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client \u001b[39m=\u001b[39m http_client \u001b[39mor\u001b[39;00m AsyncHttpxClientWrapper(\n\u001b[1;32m   1438\u001b[0m     base_url\u001b[39m=\u001b[39mbase_url,\n\u001b[1;32m   1439\u001b[0m     \u001b[39m# cast to a valid type because mypy doesn't understand our type narrowing\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     timeout\u001b[39m=\u001b[39mcast(Timeout, timeout),\n\u001b[1;32m   1441\u001b[0m     proxies\u001b[39m=\u001b[39mproxies,\n\u001b[1;32m   1442\u001b[0m     transport\u001b[39m=\u001b[39mtransport,\n\u001b[1;32m   1443\u001b[0m     limits\u001b[39m=\u001b[39mlimits,\n\u001b[1;32m   1444\u001b[0m     follow_redirects\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1445\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/PP_new/lib/python3.12/site-packages/openai/_base_client.py:1334\u001b[0m, in \u001b[0;36m_DefaultAsyncHttpxClient.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1332\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mlimits\u001b[39m\u001b[39m\"\u001b[39m, DEFAULT_CONNECTION_LIMITS)\n\u001b[1;32m   1333\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mfollow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1334\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: AsyncClient.__init__() got an unexpected keyword argument 'proxies'"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings = create_embeddings_azureopenai(AZURE_EMBEDDING_MODEL,AZURE_AOAI_API_VERSION)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1834418",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://dmn-ap26180-prod-1b000272.datalab.cloud.echonet/mnt/genai_tuto_script/c02_llm_model_connection/c021_azureopenai_connection.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(embeddings\u001b[39m.\u001b[39membed_query(text))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "print(embeddings.embed_query(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e40b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d100a24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PP_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
